{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_files_dir='sounds-with-classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sound_files_paths(sound_files_dir):\n",
    "    from os import walk\n",
    "    sound_files_paths = []\n",
    "    for (dirpath, dirnames, filenames) in walk(sound_files_dir):\n",
    "        if len(filenames) > 0:\n",
    "            for filename in filenames:\n",
    "                if len(filename) > 0 and filename[0] != '.':\n",
    "                    sound_files_paths.append('/'.join([dirpath, filename]))\n",
    "    return sound_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_files_paths = get_sound_files_paths(sound_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_full_data_from_drive(data_path):\n",
    "    class_to_file_paths = {}\n",
    "    for sound_file_path in sound_files_paths:\n",
    "        file_class = sound_file_path.split('/')[-2]\n",
    "        if file_class in class_to_file_paths:\n",
    "            class_to_file_paths[file_class].append(sound_file_path)\n",
    "        else:\n",
    "            class_to_file_paths[file_class] = [sound_file_path]\n",
    "    return class_to_file_paths\n",
    "\n",
    "def read_data_from_drive(sound_file_path):\n",
    "    from scipy.io import wavfile\n",
    "    fs, data = wavfile.read(sound_file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_file_paths = read_full_data_from_drive(sound_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_to_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(read_data_from_drive(class_to_file_paths['0'][0]), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_train_and_valid(data, valid_percent=20.0, test_percent=10.0):\n",
    "    import math\n",
    "    import random\n",
    "    train_data = {}\n",
    "    valid_data = {}\n",
    "    for class_id, sound_files_paths in data.items():\n",
    "        valid_samples_in_class = math.floor(len(sound_files_paths) * (valid_percent / 100))\n",
    "        train_sampler_in_class = len(sound_files_paths) - valid_samples_in_class\n",
    "        valid_samples_ids = random.sample(range(len(sound_files_paths)), valid_samples_in_class)\n",
    "        for i in range(len(sound_files_paths)):\n",
    "            if i in valid_samples_ids:\n",
    "                valid_data[sound_files_paths[i]] = class_id\n",
    "            else:\n",
    "                train_data[sound_files_paths[i]] = class_id\n",
    "    return (train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = split_data_to_train_and_valid(class_to_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_of_file(samples, sample_rate=44100):\n",
    "    from scipy import signal\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    return spectrogram.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_count(data):\n",
    "    items_count = 0\n",
    "    for file_path in data:\n",
    "        items_count += len(read_data_from_drive(file_path))\n",
    "    return items_count\n",
    "\n",
    "def get_spectrogram_count(data):\n",
    "    items_count = 0\n",
    "    for file_path in data:\n",
    "        items_count += get_spectrogram_of_file(read_data_from_drive(file_path)).shape[0]\n",
    "    return items_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_items_count = get_spectrogram_count(train_data)\n",
    "valid_data_items_count = get_spectrogram_count(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(class_to_file_paths):\n",
    "    vocabulary = {}\n",
    "    vocab_index = 0\n",
    "    for file_class, file_paths in class_to_file_paths.items():\n",
    "        for file_path in file_paths:\n",
    "            file_data = read_data_from_drive(file_path)\n",
    "            for file_item in file_data:\n",
    "                if file_item not in vocabulary:\n",
    "                    vocabulary[file_item] = vocab_index\n",
    "                    vocab_index += 1\n",
    "    reversed_vocabulary = dict(zip(vocabulary.values(), vocabulary.keys()))\n",
    "    return (vocabulary, reversed_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, reversed_vocabulary = build_vocabulary(class_to_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "class StepanBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, num_classes, vocabulary, skip_steps=1, freq=129):\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.skip_steps = skip_steps\n",
    "        self.vocabulary = vocabulary\n",
    "        self.freq = freq\n",
    "        \n",
    "        self.current_data = None\n",
    "        self.current_file_idx = 0\n",
    "        self.current_pos_in_file = 0\n",
    "        \n",
    "        self.current_spectrogram = None\n",
    "        self.current_pos_in_spectrogram = 0\n",
    "\n",
    "        self.file_paths = []\n",
    "        self.file_classes = []\n",
    "        for file_path, file_class in data.items():\n",
    "            self.file_paths.append(file_path)\n",
    "            self.file_classes.append(file_class)\n",
    "        self.__change_file()\n",
    "    \n",
    "    def __map_data_to_vocabulary(self, data):\n",
    "        return [self.vocabulary[d] for d in data if d in self.vocabulary]\n",
    "    \n",
    "    def __change_file(self):\n",
    "        while True:\n",
    "            try:\n",
    "                if self.current_file_idx+1 >= len(self.file_paths):\n",
    "                    self.current_file_idx = 0\n",
    "                else:\n",
    "                    self.current_file_idx += 1\n",
    "                self.current_data = read_data_from_drive(self.file_paths[self.current_file_idx])\n",
    "                self.current_spectrogram = get_spectrogram_of_file(self.current_data)\n",
    "                self.current_pos_in_file = 0\n",
    "                self.current_pos_in_spectrogram = 0\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps, self.freq))\n",
    "        y = np.zeros((self.batch_size, self.num_classes))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_pos_in_spectrogram + self.num_steps >= len(self.current_spectrogram):\n",
    "                    self.__change_file()\n",
    "                x[i, :, :] = self.current_spectrogram[self.current_pos_in_spectrogram:self.current_pos_in_spectrogram + self.num_steps, :]\n",
    "                y[i, :] = to_categorical(self.file_classes[self.current_file_idx], num_classes=self.num_classes)\n",
    "                self.current_pos_in_spectrogram += self.skip_steps\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 40\n",
    "skip_steps = 20\n",
    "batch_size = 8\n",
    "num_classes = len(class_to_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = StepanBatchGenerator(train_data, num_steps, batch_size, num_classes, vocabulary, skip_steps=skip_steps)\n",
    "valid_data_generator = StepanBatchGenerator(valid_data, num_steps, batch_size, num_classes, vocabulary, skip_steps=skip_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pieces_in_whole_sound_with_step(data_count, num_steps, skip_steps):\n",
    "    pieces = 0\n",
    "    end_piece = num_steps\n",
    "    while end_piece <= data_count:\n",
    "        pieces += 1\n",
    "        end_piece += skip_steps\n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = pieces_in_whole_sound_with_step(train_data_items_count, num_steps, skip_steps)//batch_size\n",
    "validation_steps = pieces_in_whole_sound_with_step(valid_data_items_count, num_steps, skip_steps)//batch_size\n",
    "print('Train steps: ', train_steps)\n",
    "print('Valid steps: ', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed, LSTM\n",
    "from keras.initializers import Constant, RandomNormal\n",
    "\n",
    "hidden_size = 500\n",
    "num_epochs = 50\n",
    "\n",
    "stepan_model = Sequential()\n",
    "stepan_model.add(LSTM(hidden_size, dropout=0.05, return_sequences=False, input_shape=(num_steps, 129)))\n",
    "stepan_model.add(Dense(units=num_classes, activation='softmax'))\n",
    "                 \n",
    "stepan_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "print(stepan_model.summary())\n",
    "                 \n",
    "hist = stepan_model.fit_generator(train_data_generator.generate(), train_steps, num_epochs,\n",
    "                        validation_data=valid_data_generator.generate(),\n",
    "                        validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepan_model.save(\"stepan_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "stepan_model = load_model(\"stepan_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_iters = 0\n",
    "example_training_generator = StepanBatchGenerator(valid_data, num_steps, 1, num_classes, vocabulary, skip_steps=skip_steps)\n",
    "print(\"Training data:\")\n",
    "for i in range(dummy_iters):\n",
    "    dummy = next(example_training_generator.generate())\n",
    "num_predict = 100\n",
    "for i in range(num_predict):\n",
    "    data = next(example_training_generator.generate())\n",
    "    prediction = stepan_model.predict(data[0])\n",
    "    predicted = np.argmax(prediction)\n",
    "    true = np.argmax(data[1])\n",
    "    print('Label {}: predicted: {} true: {}'.format(i, predicted, true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
